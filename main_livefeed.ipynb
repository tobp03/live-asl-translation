{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751d809a",
   "metadata": {},
   "source": [
    "# Full Pipeline for Live Sign Language Translation with Citizen ASL Dataset\n",
    "\n",
    "This notebook implements a complete pipeline for converting sign language video into live text predictions using pose estimation and a language model.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Landmark Extraction**: Extract body and hand landmarks from Citizen ASL sign videos using [MediaPipe Holistic](https://developers.google.com/mediapipe).\n",
    "2. **Preprocessing** : Normalize and split the landmark sequences into training, validation, and test sets.\n",
    "3. **Model Training** : Train a deep learning model on the preprocessed data.\n",
    "4. **Live translation** : Use a trained model and LLM in a real-time translation system.\n",
    "\n",
    "## Requirements:\n",
    "- Install dependencies via:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt \n",
    "    ```\n",
    "    **Or**, install them manually. Make sure you are using the following versions:\n",
    "    - Python: 3.10.17\n",
    "    - TensorFlow: 2.19.0\n",
    "    - MediaPipe 0.10.9\n",
    "    - OpenAI 1.82.0\n",
    "\n",
    "- Obtain an API key for a Large Language Model (LLM):\n",
    "    - This pipeline uses [OpenAI's GPT API](https://platform.openai.com/) for language enhancement in the live translation phase.\n",
    "    - Note: OpenAI is not free. You must have a valid and funded API key.\n",
    "\n",
    "- **Landmark extraction** requires [ASL Citizen Dataset](https://www.microsoft.com/en-us/research/project/asl-citizen/) downloaded\n",
    "\n",
    "> **Preprocessed data** and **model training** is available on [this notebook](https://www.kaggle.com/code/tobypu/aslcitizen-top200-training).\n",
    "\n",
    "> **Live translation** is available for testing using a trained model covering 200 unique glosses (271 total classes including duplicates). To use it, specify the path to the trained model and the accompanying index_to_glos_200.json file, which maps model outputs to gloss labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b78644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.17 | packaged by conda-forge | (main, Apr 10 2025, 22:19:12) [GCC 13.3.0]\n",
      "TensorFlow: 2.19.0\n",
      "MediaPipe: 0.10.9\n",
      "OpenAI: 1.82.0\n",
      "cv2: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import openai\n",
    "import cv2\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"MediaPipe:\", mp.__version__)\n",
    "print(\"OpenAI:\", openai.__version__)\n",
    "print(\"cv2:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21733526",
   "metadata": {},
   "source": [
    "The following modules are imported for different stages of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578393c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import asl_citizen_MP_encoding\n",
    "from utils import preprocessing_split \n",
    "from utils import train_model \n",
    "from utils import live_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62bd63",
   "metadata": {},
   "source": [
    "## 1. Landmark Extraction\n",
    "This step converts raw sign videos from the Citizen ASL dataset into landmark sequences using MediaPipe Holistic.\n",
    "\n",
    "### Input\n",
    "- Sign videos from the Citizen ASL dataset\n",
    "- Split CSV files: `train.csv`, `test.csv`, and `val.csv` under `splits/` directory\n",
    "- Citizen ASL dataset folders and videos should not be modified or renamed from their original structure.\n",
    "\n",
    "### What It Does\n",
    "For each video, the pipeline:\n",
    "1. Extracts 3D landmarks for:\n",
    "    - 33 pose landmarks\n",
    "    - 21 left-hand landmarks\n",
    "    - 21 right-hand landmarks\n",
    "    - A subset of 32 facial landmarks\n",
    "2. Combines them into `(frames, 107, 3)` NumPy array\n",
    "3. Stores only the`(x,y)` coordinates and `gloss` to a `.npz` file.\n",
    "### Output\n",
    "- One `.npz` file per video saved under `processed_save_dir`\n",
    "- Each `.npz` file contains:\n",
    "    - `landmarks`: `np.darray` of shape (frames,107,2)\n",
    "    - `gloss`: The sign label\n",
    "\n",
    "\n",
    "> **Note** : Approximately takes about 3-4 days to process all videos with Mediapipe Holistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed88aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir='/home/tob/Documents/Codes/Python/asl_live/ASL_Citizen/videos'\n",
    "processed_save_dir='/home/toby/Documents/Codes/Python/asl_live/processed_all'\n",
    "asl_citizen_MP_encoding.process_asl_dataset(video_dir,processed_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dea71f",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "This step prepared the extracted landmarks for model training by normalizing, pad the data, and encode the labels.\n",
    "\n",
    "### What It Does\n",
    "1. Generate Label and One-Hot Encoders\n",
    "    - Reads the glosses from `train.csv`, `val.csv`, or `test.csv`\n",
    "    - Creates:\n",
    "        - A label encoder (gloss -> integer)\n",
    "        - A one-hot encoder (integer -> one-hot vector)\n",
    "        - A gloss_to_index.json dictionary for mapping (gloss -> integer)\n",
    "2. Encode Labels\n",
    "    - For each `.npz` file:\n",
    "        - Loads the gloss label\n",
    "        - Converts it to one-hot format using the encoders\n",
    "    - Saves the resulting arrays as `y_train.npy`, `y_val.npy`, and `y_test.npy` under `save_dir`\n",
    "3. Preprocess Landmark Features\n",
    "    - Loads landmark arrays of shape `(frames, 107, 2)`\n",
    "    - Removes:\n",
    "        - Pose landmarks 0-10 and 23-32\n",
    "    - Pads or repeats frame to a fixed length of 150\n",
    "    - Applies normalization:\n",
    "        - Anchor-based normalization for body, face, and arm landmarks.\n",
    "        - Hand normalization to bound hand keypoints in `[-0.5,0.5]`, centered at `(0,0)`\n",
    "    - Saves the processed data as `x_train.npy`, `x_val.npy`, and `x_test.npy` in shape `(videos, 160,86 , 2)` under `save_dir`\n",
    "\n",
    "### Input\n",
    "- `.npz` files from the landmark extrtaction step (under `save_dir_name/{split}`)\n",
    "- Corresponding `train.csv`, `val.csv`, or `test.csv` file\n",
    "\n",
    "### Output\n",
    "- One-hot encoded label arrays: `y_train.npy`, `y_val.npy`, and `y_test.npy`\n",
    "- Preprocessed landmark arrays: `x_train.npy`, `x_val.npy`, and `x_test.npy`\n",
    "\n",
    "> Note: This step applies pose normalization, arm alignment, and hand bounding box to remove spatial and body proportionality bias. For a detailed explanation and justification of these choices, please refer  to [our research paper](https://doi.org/10.26877/sj5scb03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7aba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Generate Label Encoder, OneHot Encoder, and Gloss Dictionary ===\n",
    "csv_path='/home/toby/Documents/Codes/Python/Sign Transation/ASL_Citizen/splits/test.csv' #location of test/train/val.csv\n",
    "save_dict_path='/home/toby/Documents/Codes/Python/asllive/gloss_to_index' #Path and dictionary name\n",
    "label_encoder, onehot_encoder, gloss_to_index = preprocessing_split.generate_gloss_dictionary(csv_path,save_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2731"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gloss_to_index) #STRING (GlOSS) TO UNIQUE INTEGER (0-2730)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbfdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/toby/Documents/Codes/Python/asllive/model_train_data'\n",
    "processed_save_dir='/home/toby/Documents/Codes/Python/Sign Transation/processed_all'\n",
    "\n",
    "#Create y_train, y_test, and y_val\n",
    "preprocessing_split.encode_labels(label_encoder, onehot_encoder, processed_save_dir, save_dir)\n",
    "\n",
    "#Create X_train, X_test, and X_val\n",
    "preprocessing_split.preprocess_and_save_x(processed_save_dir, save_dir, split='train')\n",
    "preprocessing_split.preprocess_and_save_x(processed_save_dir, save_dir, split='test')\n",
    "preprocessing_split.preprocess_and_save_x(processed_save_dir, save_dir, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d70fe",
   "metadata": {},
   "source": [
    "### 3. Model Training\n",
    "\n",
    "This section trains a GRU-based model using the preprocessed sign language data. The training logic is defined in `train_model.py`, which consists of two main components:\n",
    "\n",
    "#### A. `data_loader(...)`\n",
    "This function loads and optionally filters the training, validation, and test datasets:\n",
    "- Loads `.npy` files containing pose features and one-hot encoded labels.\n",
    "- Due to prediction results, labels are converted back from one-hot encoded vectors into unique integer class labels.\n",
    "- Supports partial gloss filtering by mapping similar gloss variants (ex: `GO1` and `GO2` -> `GO`). \n",
    "- Optionally merges the test set into training for cases like leaderboard training.\n",
    "- Returns: tuples of `(X_train, y_train)`, `(X_val, y_val)`, `(X_test, y_test)`, and a decoder dictionary (if filtered) (decoder maps integer -> gloss).\n",
    "\n",
    "### B. `train_gru_model(...)`\n",
    "Trains a sequential GRU-based neural network using TensorFlow/Keras:\n",
    "- Two GRU layers (`386` units and followed by `192` units).\n",
    "- Dropout layers for regularization.\n",
    "- Final `Dense` layer with `softmax` for multi-class classification.\n",
    "- Automatically saves the **best-performing model** on validation accuracy.\n",
    "- If test data is passed, accuracy and macro F1 score are computed.\n",
    "- The final model is saved as `best_model.keras`.\n",
    "\n",
    "---\n",
    "\n",
    "Training was performed on **Kaggle** using GPU acceleartion. The notebook is available [here](https://www.kaggle.com/code/tobypu/aslcitizen-top200-training)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83b5e7",
   "metadata": {},
   "source": [
    "We selected the **top 200 most commonly used signs** based on [HandSpeak's list of most-used signs](https://www.handspeak.com/word/most-used/). These signs are listed in `.txt`file, each separtated by a newline. \n",
    "\n",
    "We also moved test data into train for better interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a511e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (val_X, val_y), (_, _), decoder = train_model.data_loader(\n",
    "    data_dir=\"/kaggle/input/citizen-asl-mediapipe-encoded-and-preprocessed\",\n",
    "    gloss_to_index_dir='/kaggle/input/citizen-asl-mediapipe-encoded-and-preprocessed/gloss_to_index.json',\n",
    "    filtered_txt_path=\"/kaggle/input/top200citizen/Citizen200.txt\",\n",
    "    merge_test_to_train=True\n",
    ")\n",
    "\n",
    "#Saves the mapping\n",
    "with open(\"index_to_gloss_200.json\", \"w\") as f:\n",
    "    json.dump(decoder, f, indent=2)\n",
    "\n",
    "\n",
    "model = train_model.train_gru_model(\n",
    "    train_X, train_y,\n",
    "    val_X, val_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111abb35",
   "metadata": {},
   "source": [
    "#### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec64a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">386</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">648,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">386</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">334,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">271</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,303</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m386\u001b[0m)       │       \u001b[38;5;34m648,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m386\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │       \u001b[38;5;34m334,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m271\u001b[0m)            │        \u001b[38;5;34m52,303\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,104,591</span> (11.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,104,591\u001b[0m (11.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,034,863</span> (3.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,034,863\u001b[0m (3.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,069,728</span> (7.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,069,728\u001b[0m (7.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model=load_model('/home/toby/Documents/Codes/Python/Sign Translation/best_model200.keras')\n",
    "# Show a summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e5b16",
   "metadata": {},
   "source": [
    "### 4. Live translation\n",
    "\n",
    "The `start_live_feed()` function is responsible for capturing webcam input, performing real-time sign language recognition using a trained GRU model, and generating meaningful translations through a language model (OpenAI GPT).\n",
    "\n",
    "#### Input Arguments\n",
    "   - `model_path`: Path to the `.keras` model file containing the trained GRU network for recognizing sequences of body/keypoint features.\n",
    "   - `encoder_path`: JSON file mapping predicted class indices to sign language glosses (e.g., `{0: \"HELLO\", 1: \"THANK-YOU\", ...}`).\n",
    "   - `client`: Load OpenAI API key stored in `.env`\n",
    "   - `threshold` : Controls the sensitivity to motion. A lower value makes the system more sensitive, triggering capture with smaller movements. A higher value requires more movement to start capturing, making it less sensitive. Default is `1.2` (float)\n",
    "   - `webcam` : Specifies which webcam to use webcam device. Default is `0`. If you have multiple, try `1`, `2`, etc (integer)\n",
    "   - `complexity_setting` : Sets the model complexity for the MediaPipe Holistic pipeline. (`0` : Fastest but least accurate, `1` : Balanced, `2` : Most accurate but slowest). Default is `0`\n",
    "\n",
    "#### **Flowchart Summary**\n",
    "![Flowchart](flowchart.jpg)\n",
    "\n",
    "#### **Creating `.env` API KEY file**\n",
    "1. Open a text editor and add your OpenAI API key like this:\n",
    "    ```bash\n",
    "    API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "    ```\n",
    "2. Save the file as `.env` in your project repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33410f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 12:42:33.408302: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749361353.661087   11602 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1749361353.666061   12213 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 25.0.6), renderer: AMD Radeon Graphics (radeonsi, renoir, ACO, DRM 3.61, 6.14.9-300.fc42.x86_64)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837995025448998 0.7837995025448998 0\n",
      "0.5923684700787442 0.7263701928050531 0\n",
      "0.3812120475955876 0.6228227492422134 0\n",
      "0.2940264315240235 0.5241838539267564 0\n",
      "0.26046844120414475 0.44506923010997285 0\n",
      "0.23786492936015896 0.3829079398850287 0\n",
      "0.2446950830551549 0.34144408283606653 0\n",
      "0.21812854394182796 0.30444942116779494 0\n",
      "0.2059392171071573 0.27489635994960365 0\n",
      "0.20236462266424532 0.2531368387639962 0\n",
      "0.22581143570913803 0.2449392178475387 0\n",
      "0.21135839899202993 0.23486497219088603 0\n",
      "0.21343867089801438 0.22843708180302452 0\n",
      "0.210816398588771 0.22315087683874846 0\n",
      "0.17658946464077668 0.2091824531793569 0\n",
      "0.15981910588924603 0.19437344899232362 0\n",
      "0.19715967397999984 0.19520931648862647 0\n",
      "0.3478988127991703 0.2410161653817896 0\n",
      "0.49996253260289025 0.31870007554811974 0\n",
      "0.8515407714904863 0.47855228433082975 0\n",
      "10.21902990976343 3.4006955719606093 0\n",
      "11.810676863737354 5.9236899594936325 1\n",
      "13.404152079938555 8.167828595627109 2\n",
      "15.919690407078061 10.493387139062394 3\n",
      "7.075932047947549 9.468150611727939 4\n",
      "9.996294762304462 9.626593856900897 5\n",
      "9.805451594178372 9.68025117808414 6\n",
      "10.99374567275013 10.074299526483935 7\n",
      "13.683240829038615 11.156981917250338 8\n",
      "10.596377637392024 10.988800633292843 9\n",
      "16.543830031146946 12.655309452649073 10\n",
      "13.494281606677518 12.907001098857606 11\n",
      "11.540008339568747 12.496903271070947 12\n",
      "10.735531756511554 11.968491816703128 13\n",
      "3.4319877081718966 9.407540584143758 14\n",
      "3.0598386173016783 7.503229994091134 15\n",
      "2.500521543045492 6.002417458777441 16\n",
      "2.197792349610309 4.861029926027301 17\n",
      "2.0918621090097638 4.0302795809220395 18\n",
      "1.6944820031083059 3.3295403075779193 19\n",
      "1.3908888852394117 2.747944880876367 20\n",
      "1.1708367150215047 2.274812431119908 21\n",
      "1.2355868629583227 1.9630447606714325 22\n",
      "1.1432421466019094 1.7171039764505753 23\n",
      "0.8696998768323697 1.4628827465651135 24\n",
      "0.7552150414650725 1.2505824350351011 25\n",
      "0.7574052560347323 1.1026292813349905 26\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "0.7606195732097034 1.0000263688974043 0\n",
      "0.6255544871512188 0.8876848043735486 0\n",
      "0.8296319347708532 0.87026894349274 0\n",
      "0.9760921456304372 0.9020159041340491 0\n",
      "0.950445260986692 0.9165447111898419 0\n",
      "1.0283031585034696 0.9500722453839302 0\n",
      "0.8229858875982873 0.9119463380482373 0\n",
      "0.8460169881239825 0.8921675330709609 0\n",
      "0.82069449360558 0.8707256212313466 0\n",
      "0.9201440672518612 0.8855511550375008 0\n",
      "1.05121275414718 0.9352496347704045 0\n",
      "0.8795167542486132 0.9185297706138671 0\n",
      "0.9509891128959854 0.9282675732985025 0\n",
      "1.5710231655385707 1.1210942509705228 0\n",
      "9.350702325980908 3.5899766734736382 0\n",
      "11.701721633378135 6.0235001614449875 1\n",
      "13.901278804449351 8.386833754346295 2\n",
      "17.5744405594198 11.143115795868345 3\n",
      "12.594099547330252 11.578410921306917 4\n",
      "10.979332954942945 11.398687531397725 5\n",
      "11.54380490663182 11.442222743967953 6\n",
      "15.128640903794741 12.548148191915988 7\n",
      "15.912034317623593 13.55731402962827 8\n",
      "16.90952723490619 14.562977991211643 9\n",
      "14.611111640307652 14.577418085940444 10\n",
      "7.629325932569488 12.492990439929155 11\n",
      "9.566938688227676 11.61517491441871 12\n",
      "21.20994851778115 14.493606995427442 13\n",
      "21.47007530288631 16.5865474876651 14\n",
      "20.844804567642278 17.86402461165825 15\n",
      "15.342160116063292 17.107465262979762 16\n",
      "2.158920871455136 12.622901945522374 17\n",
      "1.4673649748001159 9.276240854305696 18\n",
      "1.4527685237240449 6.929199155131201 19\n",
      "1.290727615045049 5.237657693105355 20\n",
      "1.035624976776234 3.9770478782066183 21\n",
      "0.9589683823113679 3.071624029438043 22\n",
      "1.2019148515411602 2.510711276068978 23\n",
      "1.404331611403121 2.178797376669221 24\n",
      "1.4457474160105108 1.9588823884716078 25\n",
      "1.7040572984875182 1.8824348614763808 26\n",
      "1.1790211593596374 1.6714107508413578 27\n",
      "0.917447458165203 1.4452217630385114 28\n",
      "0.9081252752777307 1.284092816710277 29\n",
      "0.6808409668500272 1.103117261752202 30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "0.6611460675563916 0.9705259034934588 0\n",
      "0.5970970649282733 0.8584972519239031 0\n",
      "0.5389690074800133 0.7626387785907361 0\n",
      "0.5195054532852476 0.6896987809990895 0\n",
      "0.8867573699050096 0.7488163576708655 0\n",
      "0.9803774364710574 0.818284681310923 0\n",
      "1.0101703076776258 0.8758503692209338 0\n",
      "1.4475670149599935 1.0473653629426516 0\n",
      "1.0630271352052878 1.0520638946214425 0\n",
      "1.1668238238173956 1.0864918733802282 0\n",
      "1.1926477065053842 1.118338623317775 0\n",
      "0.7948024738660389 1.0212777784822542 0\n",
      "0.9355378157844076 0.9955557896729001 0\n",
      "0.7598878742502285 0.9248554150460986 0\n",
      "0.6792364599580367 0.85116972851968 0\n",
      "0.5523234034089164 0.7615158309864508 0\n",
      "0.2819405718369172 0.6176432532415908 0\n",
      "0.6137725965354354 0.6164820562297442 0\n",
      "0.7480871136881108 0.6559635734672541 0\n",
      "0.8749528898081842 0.7216603683695331 0\n",
      "0.9243455500425661 0.7824659228714429 0\n",
      "0.7337546700567192 0.7678525470270258 0\n",
      "0.6746105552000266 0.739879949478926 0\n",
      "0.7571579168133978 0.7450633396792674 0\n",
      "0.7294737246019574 0.7403864551560744 0\n",
      "0.6756014988374329 0.7209509682604819 0\n",
      "0.5839294931511103 0.6798445257276704 0\n",
      "0.4461511653166549 0.6097365176043658 0\n",
      "0.48799701552261904 0.5732146669798417 0\n",
      "0.41895974577553313 0.5269381906185491 0\n",
      "0.5341738867785502 0.5291088994665494 0\n",
      "0.708479420342449 0.5829200557293193 0\n",
      "0.7252643607465615 0.6256233472344919 0\n",
      "0.9426523141417382 0.7207320373066657 0\n",
      "0.8580159885953617 0.7619172226932744 0\n",
      "0.9190140175281774 0.8090462611437452 0\n",
      "0.8996964647933388 0.8362413222386231 0\n",
      "0.7656049453148538 0.8150504091614923 0\n",
      "0.9083542855554831 0.8430415720796894 0\n",
      "0.6564382575616403 0.7870605777242747 0\n",
      "0.6172943816144549 0.7361307188913288 0\n",
      "0.5644021279758975 0.6846121416166994 0\n",
      "0.48393636034393367 0.6244094072348696 0\n",
      "0.5495686686730861 0.6019571856663345 0\n",
      "0.5960243090231929 0.600177322673392 0\n",
      "0.5915859366120626 0.5975999068549931 0\n",
      "0.4815332759898276 0.5627799175954434 0\n",
      "0.29588598207652134 0.4827117369397668 0\n",
      "0.20939939522963716 0.4007180344267279 0\n",
      "0.20350913103354973 0.34155536340877446 0\n",
      "0.3676550925837827 0.3493852821612769 0\n",
      "0.55709742065461 0.4116989237092768 0\n",
      "0.6786206692945717 0.4917754473848652 0\n",
      "0.7570154624315444 0.5713474518988689 0\n",
      "0.6508839114528536 0.5952083897650643 0\n",
      "0.5078806888118192 0.5690100794790908 0\n",
      "0.5542519194250205 0.5645826314628697 0\n",
      "0.48332448285855534 0.5402051868815754 0\n",
      "0.6077003434426165 0.5604537338498876 0\n",
      "0.6121631880254582 0.5759665701025587 0\n",
      "0.4448443245595333 0.536629896439651 0\n",
      "0.37330023910824633 0.48763099924022957 0\n",
      "0.28129944819739666 0.42573153392737967 0\n",
      "0.3802331108923222 0.41208200701686243 0\n",
      "0.4384952869498617 0.42000599099676217 0\n",
      "0.5033712968936496 0.44501558276582837 0\n",
      "0.39770042166053465 0.43082103443424025 0\n",
      "0.288608209999579 0.38815718710384184 0\n",
      "0.22806346906853014 0.3401290716932483 0\n",
      "0.39431759823158163 0.3563856296547483 0\n",
      "0.5264900015983175 0.407416941237819 0\n",
      "0.5208435283477474 0.4414449173707975 0\n",
      "0.5794361285622843 0.48284228072824353 0\n",
      "0.3467843543104291 0.4420249028028992 0\n",
      "0.228403271553238 0.37793841342800083 0\n",
      "0.221141986799082 0.3308994854393251 0\n",
      "0.3705619888705817 0.3427982364687021 0\n",
      "0.4051934136487292 0.36151678962271017 0\n",
      "0.4728235544142017 0.3949088190601576 0\n",
      "0.7011183848436346 0.4867716887952007 0\n",
      "0.9314487147645514 0.6201747965860058 0\n",
      "1.0536418072857714 0.7502148997959355 0\n",
      "1.0577173728771014 0.8424656417202852 0\n",
      "0.9981000766264037 0.8891559721921206 0\n",
      "0.6960386238621992 0.8312207676931441 0\n",
      "0.7667668195961179 0.8118845832640362 0\n",
      "0.9005334963279761 0.838479257183218 0\n",
      "0.9162786252437641 0.8618190676013818 0\n",
      "1.031812309946483 0.9128170403049122 0\n",
      "1.4220653850857607 1.0655915437391668 0\n",
      "2.103134093917589 1.3768543087926934 0\n",
      "2.4224196573076355 1.6905239133471759 1\n",
      "2.7179935601870477 1.9987648073991373 2\n",
      "9.317124230652958 4.194272634375284 3\n",
      "11.278526227324463 6.319548712260037 4\n",
      "12.357955111392403 8.131070631999746 5\n",
      "13.977874858517977 9.885111899955216 6\n",
      "14.07556306399878 11.142247249168285 7\n",
      "18.710951620150023 13.412858560462807 8\n",
      "19.79550274418081 15.327651815578207 9\n",
      "20.327887193104242 16.82772242883602 10\n",
      "15.293329774433804 16.367404632515353 11\n",
      "8.940316657455403 14.139278239997367 12\n",
      "8.189835030385916 12.35444527711393 13\n",
      "7.648028126743538 10.942520132002812 14\n",
      "6.965736642030315 9.749485085011063 15\n",
      "7.355517611943371 9.031294843090755 16\n",
      "12.329874233882169 10.02086866032818 17\n",
      "10.482476998679648 10.15935116183362 18\n",
      "9.10338705043991 9.842561928415506 19\n",
      "14.739704816695664 11.311704794899553 20\n",
      "11.291879992691142 11.305757354237029 21\n",
      "16.634561523315746 12.904398604960644 22\n",
      "23.46063328404329 16.071269008685437 23\n",
      "18.114158565696687 16.68413587578881 24\n",
      "16.970116986069126 16.769930208872907 25\n",
      "17.731412912813163 17.05837502005498 26\n",
      "11.368618029773186 15.351447922970442 27\n",
      "17.530657875442444 16.005210908712044 28\n",
      "22.81938051411758 18.049461790333705 29\n",
      "18.513873560733554 18.188785321453658 30\n",
      "18.23898436231935 18.203845033713364 31\n",
      "10.52354532253207 15.899755120358975 32\n",
      "3.1819898490538208 12.084425538967428 33\n",
      "1.3434796670580091 8.862141777394603 34\n",
      "1.1139052530495208 6.537670820091078 35\n",
      "0.9502865541346107 4.861455540304138 36\n",
      "1.2215463046914614 3.7694827696203346 37\n",
      "1.1786115608999095 2.992221407004207 38\n",
      "1.2728409141067996 2.476407259134985 39\n",
      "1.2729457985614525 2.1153688209629253 40\n",
      "1.242194127520961 1.8534164129303359 41\n",
      "1.3071898654220586 1.6895484486778525 42\n",
      "1.284106426055342 1.5679158418910992 43\n",
      "1.3316261619906524 1.4970289379209651 44\n",
      "0.9434327997761371 1.3309500964775167 45\n",
      "0.8991175425692526 1.2014003303050373 46\n",
      "0.7804249215088559 1.0751077076661828 47\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "0.6867621416602665 0.9586040378644078 0\n",
      "0.9561454713851436 0.9578664679206286 0\n",
      "0.8872274228466441 0.9366747543984332 0\n",
      "0.866155273859559 0.9155189102367709 0\n",
      "0.9806410895239317 0.935055564022919 0\n",
      "0.6813624729863762 0.8589476367119561 0\n",
      "0.6290088388899919 0.7899659973653668 0\n",
      "0.7388944213192592 0.7746445245515344 0\n",
      "0.9809058553189701 0.8365229237817651 0\n",
      "1.0567823302011323 0.9026007457075753 0\n",
      "1.0675148554014766 0.9520749786157456 0\n",
      "1.1260510761273999 1.004267807869242 0\n",
      "0.8095604392864542 0.9458555972944056 0\n",
      "0.7699467482249677 0.8930829425735742 0\n",
      "0.7021373226490435 0.835799256596215 0\n",
      "0.7590653463191257 0.8127790835130881 0\n",
      "0.7203504213630237 0.7850504848680687 0\n",
      "0.8158618616768132 0.794293897910692 0\n",
      "0.8838110738787273 0.8211490507011026 0\n",
      "0.6921410532747666 0.7824466514732017 0\n",
      "0.6796169319405735 0.7515977356134133 0\n",
      "1.0418244259839295 0.8386657427245681 0\n",
      "1.1047207214607535 0.9184822363454237 0\n",
      "1.5256356153871575 1.1006282500579438 0\n",
      "1.6679274812236067 1.2708180194076426 0\n",
      "1.4023445356961088 1.3102759742941825 1\n",
      "1.2936574396623466 1.3052904139046317 2\n",
      "0.7537126508838666 1.1398170849984022 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "0.6747165615336469 1.0002869279589754 0\n",
      "0.49323849693073035 0.8481723986505019 0\n",
      "0.5294748198260247 0.7525631250031587 0\n",
      "0.5924086233364604 0.7045167745031492 0\n",
      "0.69787378931442 0.7025238789465305 0\n",
      "0.8424140125433046 0.7444909190255626 0\n",
      "0.8336373566468389 0.7712348503119455 0\n",
      "0.8175201578960419 0.7851204425871744 0\n"
     ]
    }
   ],
   "source": [
    "client = live_translation.get_client('/home/toby/Documents/Codes/Python/Sign Translation/.env') \n",
    "\n",
    "live_translation.start_live_feed(model_path='/home/toby/Documents/Codes/Python/asllive/model/best_model200.keras',\n",
    "                encoder_path='/home/toby/Documents/Codes/Python/asllive/model/index_to_gloss_200.json',\n",
    "                client=client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
